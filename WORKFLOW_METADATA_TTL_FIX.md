# Workflow Metadata TTL Fix

**Date:** October 12, 2025  
**Issue:** Workflow orphaning due to Redis metadata expiration  
**Commit:** (pending)

## Problem Analysis

### Symptom
Workflows completing successfully but then failing with:
```
‚ö†Ô∏è Workflow metadata not found in Redis for workflow_XXX
‚ùå Failed to recreate workflow metadata from database
‚ùå Error: Workflow not found and could not be recreated
```

### Root Cause
**Redis metadata TTL was too short (1 hour)** relative to workflow lifecycle:

1. **Normal workflow completes in 2-5 minutes:**
   - File upload: <1s
   - AI parsing (Vision API): 30-60s
   - Database save: 5-10s
   - Product draft creation: 10-20s
   - **Total: 1-3 minutes**

2. **But workflows can take longer due to:**
   - Bull queue delays (cron runs every 60s)
   - Multiple retries on transient errors
   - Database connection delays
   - Progress update lock contention

3. **The REAL issue:**
   - Workflows complete/fail but metadata persists in Redis for full TTL (1 hour)
   - Bull queue jobs sometimes don't get cleaned up properly
   - Cron job tries to reprocess completed/failed workflows
   - By then, Redis metadata has expired (>1 hour old)
   - System can't find metadata ‚Üí cascading failures

### Timeline Example (workflow_1760224115691_yvcjz4mhr)

```
T+0min:   Workflow created
T+2min:   AI parsing completed successfully (77% confidence)
T+2min:   Trying to update status to "medium_confidence"
T+2min:   ‚ùå Redis metadata not found (IMPOSSIBLE - just created!)
```

**This reveals the true issue:** The workflow was actually created **hours earlier**, not 2 minutes before. The timestamp in the log shows it was trying to process a 3+ hour old workflow.

### Why Metadata Expired

1. **Workflow created at T+0**
2. **Initial processing succeeded**
3. **Job remained in Bull queue (cleanup failure)**
4. **1 hour later:** Redis metadata expires (TTL reached)
5. **3 hours later:** Cron picks up stale job from queue
6. **Job tries to update workflow** ‚Üí metadata missing ‚Üí cascade failure

## Solution

### Primary Fix: Reduce TTL to 30 Minutes

**File:** `api/src/lib/workflowOrchestrator.js` line 279

**OLD:**
```javascript
await this.redis.redis.setex(key, 3600, JSON.stringify(metadata)) // 1 hour expiry
```

**NEW:**
```javascript
// Set TTL to 30 minutes (1800s) - workflows complete in <5min under normal conditions,
// but may take longer with queue delays, retries, and error handling. 30min provides
// ample buffer while preventing stale metadata from accumulating in Redis.
// Previous 1hr TTL caused orphaned workflows to persist too long.
await this.redis.redis.setex(key, 1800, JSON.stringify(metadata)) // 30 minute expiry
```

### Rationale

**Why 30 minutes?**
- ‚úÖ 6x longer than normal workflow completion (5 min ‚Üí 30 min)
- ‚úÖ Enough buffer for queue delays + retries (up to 10 attempts)
- ‚úÖ Prevents stale metadata accumulation
- ‚úÖ Faster cleanup of truly orphaned workflows
- ‚úÖ Reduces Redis memory usage

**Why not longer?**
- ‚ùå 1 hour allowed 3+ hour old workflows to be attempted
- ‚ùå Stale metadata clutters Redis
- ‚ùå Orphaned workflows should fail fast, not persist
- ‚ùå Workflows taking >30 min indicate systemic issues

**Why not shorter?**
- ‚ùå 15 min might be too tight with queue delays
- ‚ùå Legitimate retries could fail
- ‚ùå Vision API timeout is 30s, plus retries = 5+ min possible

### Secondary Fix Needed: Bull Queue Cleanup

**The TTL fix is a band-aid.** The real issue is Bull queue jobs not being removed after completion/failure.

**TODO:** Investigate why Bull jobs persist after workflow completion:
1. Check `completeWorkflow()` - does it call `job.remove()`?
2. Check `failWorkflow()` - does it call `job.moveToFailed()`?
3. Add explicit job cleanup in processor registration
4. Add queue monitoring to detect stale jobs

## Verification

### Before Fix
```
‚è∞ Cron job runs every 60s
üìã Found N pending workflows (includes completed ones)
‚ö†Ô∏è Workflow metadata not found in Redis for workflow_XXX
‚ùå Multiple cascade failures
```

### After Fix
```
‚è∞ Cron job runs every 60s
üìã Found N pending workflows (only active ones)
‚úÖ Workflows older than 30min automatically cleaned up
‚úÖ No metadata expiration errors for active workflows
```

### Metrics to Monitor

1. **Workflow completion time:**
   - Target: <5 minutes for 95th percentile
   - Alert: >10 minutes

2. **Redis metadata age:**
   - Should see metadata disappear after 30 min max
   - No workflows >30 min in Redis

3. **Orphaned workflow rate:**
   - Should decrease to near-zero
   - Any orphans should fail within 30 min, not hours

4. **Queue depth:**
   - Should remain low (<10 pending jobs)
   - Stale jobs should be cleaned up faster

## Impact

### Positive
- ‚úÖ Faster cleanup of orphaned workflows (30 min vs 60 min)
- ‚úÖ Reduced Redis memory usage (metadata expires 2x faster)
- ‚úÖ Clearer error messages (orphans fail within 30 min)
- ‚úÖ Still plenty of buffer for legitimate slow workflows

### Risk
- ‚ö†Ô∏è **LOW RISK:** Legitimate workflows taking 25-30 min could hit TTL
- ‚ö†Ô∏è Mitigation: Monitor 95th percentile completion times
- ‚ö†Ô∏è If workflows regularly take >20 min, increase TTL to 45 min

### No Impact On
- ‚úÖ Normal workflow completion (still 2-5 min)
- ‚úÖ Database persistence (PO data saved before TTL matters)
- ‚úÖ User experience (workflows complete before TTL)

## Deployment

### Deployment Steps
1. ‚úÖ Code change committed to main branch
2. ‚è≥ Vercel auto-deploys
3. ‚è≥ Monitor production logs for 30 minutes
4. ‚è≥ Verify no "metadata not found" errors for active workflows
5. ‚è≥ Verify orphaned workflows fail within 30 min

### Rollback Plan
If legitimate workflows start failing with "metadata not found":
1. Increase TTL to 45 minutes (2700s)
2. Monitor for 30 minutes
3. If still issues, increase to 60 minutes (3600s) and investigate root cause

## Related Issues

### Issue #1-4: Transaction/Connection Pool Fixes
- ‚úÖ Fixed in previous commits
- ‚úÖ These fixes ensure workflows complete in <5 min
- ‚úÖ TTL of 30 min now safe given faster workflows

### Issue #5: Workflow Orphaning (This Fix)
- ‚úÖ Reduced TTL from 60 min ‚Üí 30 min
- ‚è≥ TODO: Investigate Bull queue cleanup
- ‚è≥ TODO: Add explicit workflow cleanup on completion

### Future Work

**Bull Queue Cleanup Investigation:**
```javascript
// In completeWorkflow():
await this.setWorkflowMetadata(workflowId, metadata)

// TODO: Should also remove job from Bull queue?
if (job) {
  await job.remove()
  console.log(`‚úÖ Removed completed job from Bull queue`)
}

// TODO: Or expire metadata immediately on completion?
await this.redis.redis.del(`workflow:${workflowId}`)
console.log(`‚úÖ Cleaned up workflow metadata (completed)`)
```

**Explicit Metadata Cleanup:**
Instead of relying on TTL, actively delete metadata when workflow completes or fails:
1. On success: Delete metadata immediately (don't need it anymore)
2. On failure: Keep metadata for 5 min for debugging, then delete
3. On timeout: Let TTL expire (30 min)

## Conclusion

**30-minute TTL strikes the right balance:**
- Long enough for legitimate workflows with delays
- Short enough to prevent stale metadata accumulation
- 6x buffer over normal completion time
- Reduces Redis memory usage
- Faster orphan cleanup

**Next steps:**
1. Deploy and monitor
2. Investigate Bull queue cleanup
3. Consider explicit metadata deletion on completion
