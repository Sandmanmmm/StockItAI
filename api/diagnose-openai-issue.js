#!/usr/bin/env node

/**
 * OpenAI API Diagnostic Tool
 * Identifies the root cause of API access issues
 */

import { OpenAI } from 'openai'
import dotenv from 'dotenv'

dotenv.config()

async function diagnoseOpenAIIssue() {
  console.log('üîç OpenAI API Diagnostic Tool')
  console.log('='.repeat(50))
  console.log(`üìÖ Date: ${new Date().toISOString()}`)
  
  // Check environment setup
  const apiKey = process.env.OPENAI_API_KEY
  
  if (!apiKey) {
    console.log('‚ùå OPENAI_API_KEY not found in environment')
    return false
  }
  
  console.log(`üîë API Key found: ${apiKey.substring(0, 20)}...${apiKey.substring(apiKey.length - 4)}`)
  console.log(`üìè API Key length: ${apiKey.length} characters`)
  
  // Validate key format
  if (!apiKey.startsWith('sk-')) {
    console.log('‚ùå Invalid API key format - should start with "sk-"')
    return false
  }
  
  console.log('‚úÖ API key format appears valid')
  
  // Initialize OpenAI client with minimal configuration
  const openai = new OpenAI({
    apiKey: apiKey,
    timeout: 30000, // 30 second timeout
    maxRetries: 0   // No retries for diagnostic
  })
  
  console.log('\nüìã Running Diagnostic Tests...\n')
  
  // Test 1: Basic API connectivity
  console.log('1Ô∏è‚É£ Testing basic API connectivity...')
  try {
    // Try the most basic possible request
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: 'Hi' }],
      max_tokens: 5,
      temperature: 0
    })
    
    console.log('‚úÖ Basic connectivity successful')
    console.log(`   Response: ${response.choices[0].message.content}`)
    console.log(`   Tokens: ${response.usage.total_tokens}`)
    console.log(`   Model: ${response.model}`)
    
  } catch (error) {
    console.log('‚ùå Basic connectivity failed')
    console.log(`   Error Type: ${error.constructor.name}`)
    console.log(`   HTTP Status: ${error.status || 'N/A'}`)
    console.log(`   Error Code: ${error.code || 'N/A'}`)
    console.log(`   Message: ${error.message}`)
    
    if (error.response) {
      console.log(`   Response Headers: ${JSON.stringify(error.response.headers, null, 2)}`)
      if (error.response.data) {
        console.log(`   Response Data: ${JSON.stringify(error.response.data, null, 2)}`)
      }
    }
    
    // Analyze specific error types
    if (error.status === 429) {
      console.log('\nüîç Rate Limit Analysis:')
      console.log('   This is a rate limiting error, not a quota error')
      console.log('   Possible causes:')
      console.log('   ‚Ä¢ Too many requests per minute (RPM limit)')
      console.log('   ‚Ä¢ Too many tokens per minute (TPM limit)')
      console.log('   ‚Ä¢ Burst rate limiting')
      
      // Check rate limit headers if available
      if (error.response?.headers) {
        const headers = error.response.headers
        console.log('\n   Rate Limit Headers:')
        Object.keys(headers).forEach(key => {
          if (key.toLowerCase().includes('rate') || key.toLowerCase().includes('limit')) {
            console.log(`   ${key}: ${headers[key]}`)
          }
        })
      }
      
    } else if (error.status === 401) {
      console.log('\nüîç Authentication Analysis:')
      console.log('   This is an authentication error')
      console.log('   Possible causes:')
      console.log('   ‚Ä¢ Invalid API key')
      console.log('   ‚Ä¢ API key has been revoked or expired')
      console.log('   ‚Ä¢ API key lacks necessary permissions')
      
    } else if (error.status === 403) {
      console.log('\nüîç Authorization Analysis:')
      console.log('   This is an authorization/access error')
      console.log('   Possible causes:')
      console.log('   ‚Ä¢ Account has insufficient credits/quota')
      console.log('   ‚Ä¢ Account is suspended or restricted')
      console.log('   ‚Ä¢ Model access not permitted for this key')
      
    } else if (error.message.toLowerCase().includes('quota')) {
      console.log('\nüîç Quota Analysis:')
      console.log('   This appears to be a quota-related error')
      console.log('   Possible causes:')
      console.log('   ‚Ä¢ Monthly usage quota exceeded')
      console.log('   ‚Ä¢ Account billing issues')
      console.log('   ‚Ä¢ Free tier limitations')
    }
  }
  
  // Test 2: Try different models to isolate the issue
  console.log('\n2Ô∏è‚É£ Testing different models...')
  
  const modelsToTest = [
    'gpt-3.5-turbo',
    'gpt-4o-mini',
    'gpt-4'
  ]
  
  for (const model of modelsToTest) {
    console.log(`   Testing ${model}...`)
    try {
      const response = await openai.chat.completions.create({
        model: model,
        messages: [{ role: 'user', content: 'Test' }],
        max_tokens: 1,
        temperature: 0
      })
      console.log(`   ‚úÖ ${model} - Working (${response.usage.total_tokens} tokens)`)
    } catch (error) {
      if (error.status === 404) {
        console.log(`   ‚ö†Ô∏è ${model} - Not accessible (model not found)`)
      } else {
        console.log(`   ‚ùå ${model} - Error: ${error.message}`)
      }
    }
  }
  
  // Test 3: Check account/usage information
  console.log('\n3Ô∏è‚É£ Attempting to check account information...')
  try {
    // Try to list available models (this gives info about account status)
    const models = await openai.models.list()
    console.log(`‚úÖ Successfully retrieved models list (${models.data.length} models available)`)
    
    // Show available models
    console.log('   Available models:')
    const relevantModels = models.data
      .filter(model => model.id.includes('gpt'))
      .slice(0, 5) // Show first 5 GPT models
    
    relevantModels.forEach(model => {
      console.log(`   ‚Ä¢ ${model.id} (owned by: ${model.owned_by})`)
    })
    
    if (relevantModels.length === 0) {
      console.log('   ‚ö†Ô∏è No GPT models found in account')
    }
    
  } catch (error) {
    console.log(`‚ùå Could not retrieve account information: ${error.message}`)
  }
  
  // Test 4: Try minimal request with different parameters
  console.log('\n4Ô∏è‚É£ Testing with minimal parameters...')
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: '1' }],
      max_tokens: 1
    })
    console.log('‚úÖ Minimal request successful')
    console.log(`   Response: "${response.choices[0].message.content}"`)
  } catch (error) {
    console.log(`‚ùå Minimal request failed: ${error.message}`)
  }
  
  // Test 5: Raw HTTP request to isolate SDK issues
  console.log('\n5Ô∏è‚É£ Testing raw HTTP request...')
  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'Hi' }],
        max_tokens: 1
      })
    })
    
    console.log(`   HTTP Status: ${response.status}`)
    console.log(`   Status Text: ${response.statusText}`)
    
    if (response.ok) {
      const data = await response.json()
      console.log('‚úÖ Raw HTTP request successful')
      console.log(`   Response: ${data.choices[0].message.content}`)
    } else {
      const errorData = await response.text()
      console.log('‚ùå Raw HTTP request failed')
      console.log(`   Error Response: ${errorData}`)
    }
    
  } catch (error) {
    console.log(`‚ùå Raw HTTP request error: ${error.message}`)
  }
  
  console.log('\nüìä Diagnostic Summary:')
  console.log('='.repeat(50))
  console.log('If the issue persists, check:')
  console.log('‚Ä¢ OpenAI Dashboard: https://platform.openai.com/usage')
  console.log('‚Ä¢ Billing Status: https://platform.openai.com/account/billing')
  console.log('‚Ä¢ API Key Status: https://platform.openai.com/api-keys')
  console.log('‚Ä¢ Rate Limits: https://platform.openai.com/docs/guides/rate-limits')
  
  return true
}

// Run diagnostics
diagnoseOpenAIIssue().catch(console.error)